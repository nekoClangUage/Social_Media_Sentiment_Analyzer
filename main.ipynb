{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### Initial settings and parameters for Pandas, SciKit-learn etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# --- One-time setup: Download necessary NLTK data ---\n",
    "print(\"Paths for NLTK:\")\n",
    "print(nltk.data.path)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Reading of .CSV and working with Sentimement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaries = pd.read_csv('sentimentdataset.csv')\n",
    "commentaries = commentaries[['Text', 'Sentiment']]\n",
    "print(commentaries.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = commentaries[['Sentiment']].value_counts().reset_index()\n",
    "sentiment_counts.columns = ['Sentiment', 'Count']\n",
    "\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Positive': 'Positive',\n",
    "    'Joy': 'Positive',\n",
    "    'Excitement': 'Positive',\n",
    "    'Neutral': 'Neutral',\n",
    "    'Happy': 'Positive',\n",
    "    'Contentment': 'Positive',\n",
    "    'Sad': 'Negative',\n",
    "    'Hopeful': 'Positive',\n",
    "    'Gratitude': 'Positive',\n",
    "    'Curiosity': 'Neutral',\n",
    "    'Embarrassed': 'Negative',\n",
    "    'Loneliness': 'Negative',\n",
    "    'Hate': 'Negative',\n",
    "    'Bad': 'Negative',\n",
    "    'Playful': 'Positive',\n",
    "    'Despair': 'Negative',\n",
    "    'Elation': 'Positive',\n",
    "    'Confusion': 'Neutral',\n",
    "    'Acceptance': 'Neutral',\n",
    "    'Inspired': 'Positive',\n",
    "    'Frustrated': 'Negative',\n",
    "    'Bitterness': 'Negative',\n",
    "    'Indifference': 'Neutral',\n",
    "    'Nostalgia': 'Neutral',\n",
    "    'Serenity': 'Positive',\n",
    "    'Ambivalence': 'Neutral',\n",
    "    'Numbness': 'Neutral',\n",
    "    'Determination': 'Positive',\n",
    "    'Enthusiasm': 'Positive',\n",
    "    'Empowerment': 'Positive',\n",
    "    'Melancholy': 'Negative',\n",
    "    'Proud': 'Positive',\n",
    "    'Betrayal': 'Negative',\n",
    "    'Arousal': 'Positive',\n",
    "    'Grateful': 'Positive',\n",
    "    'Negative': 'Negative',\n",
    "    'Euphoria': 'Positive',\n",
    "    'Hope': 'Positive',\n",
    "    'Tenderness': 'Positive',\n",
    "    'Desolation': 'Negative',\n",
    "    'Compassionate': 'Positive',\n",
    "    'Inspiration': 'Positive',\n",
    "    'Frustration': 'Negative',\n",
    "    'Grief': 'Negative',\n",
    "    'Awe': 'Positive',\n",
    "    'Empathetic': 'Positive',\n",
    "    'Accomplishment': 'Positive',\n",
    "    'Pride': 'Positive',\n",
    "    'Free-spirited': 'Positive',\n",
    "    'Envious': 'Negative',\n",
    "    'Boredom': 'Negative',\n",
    "    'Overwhelmed': 'Negative',\n",
    "    'Dismissive': 'Negative',\n",
    "    'Devastated': 'Negative',\n",
    "    'Calmness': 'Positive',\n",
    "    'Surprise': 'Neutral',\n",
    "    'Fearful': 'Negative',\n",
    "    'Adventure': 'Positive',\n",
    "    'Resentment': 'Negative',\n",
    "    'Regret': 'Negative',\n",
    "    'Bitter': 'Negative',\n",
    "    'Confident': 'Positive',\n",
    "    'Kind': 'Positive',\n",
    "    'Jealous': 'Negative',\n",
    "    'Zest': 'Positive',\n",
    "    'Fear': 'Negative',\n",
    "    'Love': 'Positive',\n",
    "    'Envy': 'Negative',\n",
    "    'Enjoyment': 'Positive',\n",
    "    'Enchantment': 'Positive',\n",
    "    'Mischievous': 'Positive',\n",
    "    'Yearning': 'Neutral',\n",
    "    'Whimsy': 'Positive',\n",
    "    'Tranquility': 'Positive',\n",
    "    'Thrill': 'Positive',\n",
    "    'Adoration': 'Positive',\n",
    "    'Affection': 'Positive',\n",
    "    'Disgust': 'Negative',\n",
    "    'Disappointed': 'Negative',\n",
    "    'Disappointment': 'Negative',\n",
    "    'Admiration': 'Positive',\n",
    "    'Exploration': 'Positive',\n",
    "    'Heartbreak': 'Negative',\n",
    "    'Happiness': 'Positive',\n",
    "    'Fulfillment': 'Positive',\n",
    "    'Isolation': 'Negative',\n",
    "    'Creativity': 'Positive',\n",
    "    'Contemplation': 'Neutral',\n",
    "    'Coziness': 'Positive',\n",
    "    'Reflection': 'Neutral',\n",
    "    'Shame': 'Negative',\n",
    "    'Captivation': 'Positive',\n",
    "    'Emotion': 'Neutral',\n",
    "    'Amusement': 'Positive',\n",
    "    'Rejuvenation': 'Positive',\n",
    "    'Reverence': 'Positive',\n",
    "    'Satisfaction': 'Positive',\n",
    "    'Sadness': 'Negative',\n",
    "    'Anger': 'Negative',\n",
    "    'Anticipation': 'Positive',\n",
    "    'Apprehensive': 'Negative',\n",
    "    'Anxiety': 'Negative',\n",
    "    'Appreciation': 'Positive',\n",
    "    'Resilience': 'Positive',\n",
    "    'Romance': 'Positive',\n",
    "    'Ruins': 'Negative',\n",
    "    'Runway Creativity': 'Positive',\n",
    "    'Relief': 'Positive',\n",
    "    'Renewed Effort': 'Positive',\n",
    "    'Solace': 'Positive',\n",
    "    'Solitude': 'Neutral',\n",
    "    'Sorrow': 'Negative',\n",
    "    'Spark': 'Positive',\n",
    "    'Success': 'Positive',\n",
    "    'Confidence': 'Positive',\n",
    "    'Connection': 'Positive',\n",
    "    'Celebration': 'Positive',\n",
    "    'Celestial Wonder': 'Positive',\n",
    "    'Challenge': 'Neutral',\n",
    "    'Charm': 'Positive',\n",
    "    'Colorful': 'Positive',\n",
    "    'Bittersweet': 'Neutral',\n",
    "    'Blessed': 'Positive',\n",
    "    'Breakthrough': 'Positive',\n",
    "    'Ecstasy': 'Positive',\n",
    "    'Elegance': 'Positive',\n",
    "    'EmotionalStorm': 'Negative',\n",
    "    'Heartache': 'Negative',\n",
    "    'Heartwarming': 'Positive',\n",
    "    'Helplessness': 'Negative',\n",
    "    'Harmony': 'Positive',\n",
    "    'Freedom': 'Positive',\n",
    "    'Friendship': 'Positive',\n",
    "    'Grandeur': 'Positive',\n",
    "    'JoyfulReunion': 'Positive',\n",
    "    'Kindness': 'Positive',\n",
    "    'LostLove': 'Negative',\n",
    "    'Journey': 'Neutral',\n",
    "    'Joy in Baking': 'Positive',\n",
    "    'InnerJourney': 'Neutral',\n",
    "    'Intimidation': 'Negative',\n",
    "    'Intrigue': 'Positive',\n",
    "    'Creative Inspiration': 'Positive',\n",
    "    'Culinary Adventure': 'Positive',\n",
    "    'Exhaustion': 'Negative',\n",
    "    'FestiveJoy': 'Positive',\n",
    "    'Envisioning History': 'Neutral',\n",
    "    'Energy': 'Positive',\n",
    "    'Engagement': 'Positive',\n",
    "    'Hypnotic': 'Positive',\n",
    "    'Iconic': 'Positive',\n",
    "    'Imagination': 'Positive',\n",
    "    'Immersion': 'Positive',\n",
    "    'Overjoyed': 'Positive',\n",
    "    'Pensive': 'Neutral',\n",
    "    'PlayfulJoy': 'Positive',\n",
    "    'Obstacle': 'Negative',\n",
    "    \"Ocean's Freedom\": 'Positive',\n",
    "    'Optimism': 'Positive',\n",
    "    'Miscalculation': 'Negative',\n",
    "    'Motivation': 'Positive',\n",
    "    \"Nature's Beauty\": 'Positive',\n",
    "    'Positivity': 'Positive',\n",
    "    'Pressure': 'Negative',\n",
    "    'Radiance': 'Positive',\n",
    "    'DreamChaser': 'Positive',\n",
    "    'Desperation': 'Negative',\n",
    "    'CulinaryOdyssey': 'Positive',\n",
    "    'Darkness': 'Negative',\n",
    "    'Dazzle': 'Positive',\n",
    "    'Marvel': 'Positive',\n",
    "    'Melodic': 'Positive',\n",
    "    'Mesmerizing': 'Positive',\n",
    "    'Mindfulness': 'Positive',\n",
    "    'Whispers of the Past': 'Neutral',\n",
    "    'Winter Magic': 'Positive',\n",
    "    'Wonder': 'Positive',\n",
    "    'Wonderment': 'Positive',\n",
    "    'Thrilling Journey': 'Positive',\n",
    "    'Touched': 'Positive',\n",
    "    'Triumph': 'Positive',\n",
    "    'Vibrancy': 'Positive',\n",
    "    'Suffering': 'Negative',\n",
    "    'Suspense': 'Neutral',\n",
    "    'Sympathy': 'Positive',\n",
    "    'ArtisticBurst': 'Positive',\n",
    "    'Amazement': 'Positive',\n",
    "    'Adrenaline': 'Positive',\n",
    "    'Admiration': 'Positive',\n",
    "    'Betrayal': 'Negative',\n",
    "    'Jealousy': 'Negative',\n",
    "    'Loss': 'Negative',\n",
    "    'Compassion': 'Positive'\n",
    "}\n",
    "commentaries['Sentiment'] = commentaries['Sentiment'].str.strip()\n",
    "commentaries['Sentiment'] = commentaries['Sentiment'].str.lower()\n",
    "mapping_lower = {k.lower().strip(): v for k, v in mapping.items()}\n",
    "\n",
    "commentaries['Sentiment'] = commentaries['Sentiment'].replace(mapping_lower)\n",
    "\n",
    "commentaries.to_csv('./sentimentdataset_sentimentsChanged.csv')\n",
    "print(\"Unique values after replacement:\")\n",
    "print(commentaries['Sentiment'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_with_nltk(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans and normalizes a string:\n",
    "      - lowercases\n",
    "      - strips URLs\n",
    "      - removes non-alpha chars\n",
    "      - tokenizes\n",
    "      - removes stopwords & short tokens\n",
    "      - lemmatizes\n",
    "      - rejoins tokens to a cleaned string\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing stopwords and short tokens -> then lemmatize\n",
    "    clean_tokens = [\n",
    "        lemmatizer.lemmatize(tok)\n",
    "        for tok in tokens\n",
    "        if tok not in stop_words and len(tok) > 2\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(clean_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Training of the model MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaries['clean_text'] = commentaries['Text'].astype(str).apply(preprocess_with_nltk)\n",
    "\n",
    "commentaries.to_csv('./preprocessed_text_and_sentiments.csv')\n",
    "\n",
    "X = commentaries['clean_text']\n",
    "y = commentaries['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', max_df=0.80, min_df=4)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNextTextSentiment(text: str) -> str:\n",
    "    vec = vect.transform([text])\n",
    "    return clf.predict(vec)[0]\n",
    "\n",
    "examples = [\n",
    "    \"I absolutely loved this product!\",\n",
    "    \"Worst experience ever. Do not buy.\",\n",
    "    \"It was okay, not great but not bad.\",\n",
    "    \"If you would like to die, you have really big problems...\",\n",
    "    \"Meow, i am cat girl!\",\n",
    "    \"Bad product, dislike. I wouldn't buy this shit again, guys : (\",\n",
    "    \"Cool product. I love it. Thanks for developers\"\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    print(predictNextTextSentiment(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV_Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
